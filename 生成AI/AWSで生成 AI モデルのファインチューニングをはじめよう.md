# なぜ生成AIモデルをファインチューニングするのか
## RAG
検索システムのレスポンスを元に基盤モデルに回答を出力させるアプローチ<br>
基盤モデル自体には手をいれずに外部にある検索システムに手を入れることによって外部から知識を補完<br>
最新情報を出力に反映させたいケースで有効<br>
プロンプト内で与えられた知識のみで十分対応可能なケースで有効<br>

## ファインチューニング
独自データを用いて追加の学習を行うことで、モデル自体のカスタマイズを行うアプローチ<br>
出力のスタイルやドメイン知識の補完など、モデルの振る舞いをカスタマイズしたいケースに有効<br>
特定ユースケースにおける推論のコストパフォーマンスを最大限高めたいケースに有効<br>

## ファインチューニングの目的
特定のスタイルによるレスポンス
ドメイン知識の補完
特定のタスクへのコストパフォーマンス

# AWS上で生成AIモデルをファインチューニングするには
## ファインチューニングのアプローチ
下記の二つがある
### ラベルあり
主に出力のスタイルをカスタマイズしたい場合に有効<br>
入力と出力のペアを用意してファインチューニングを行う<br>

### ラベルなし
主にドメイン知識を補完したい場合に有効<br>
テキストデータを用意してファインチューニングを行う<br>

## ファインチューニングする際の選択肢
下記の二つがある
### Amazon Bedrock
サーバレスなAPI経由で基盤モデルを使用して生成AIアプリケーションを構築<br>
ラベルのありはFinetuning<br>
ラベルのなしはContinued Pretraining<br>

### Amazon SageMaker JumpStart
基盤モデルを含む学習済みMLモデルを簡単にデプロイ<br>
ラベルのありはInstruction-based fine-tuning<br>
ラベルのなしはDomain adaptation fine-tuning<br>
ファインチューニング実行時に、instruction_tunedのパラメータのTrue/Falseによって切り替え<br>

## ファインチューニングにおける比較
### Amazon Bedrock
ファインチューニングのためのコードは実装済み<br>
ミニマルなハイパーパラメータ設定<br>
推論時はProvisioned Throughput購入が必須。Bedrock APIで推論<br>

### Amazon SageMaker JumpStart
ファインチューニングのためのコードは実装済み<br>
LoRAチューニング、量子化といった詳細なハイパーパラメータ設定可能<br>
推論時は自身でインスタンスサイズ等を選定可能。SageMakerの推論機能と連携<br>

# 生成AIモデルのファインチューニングとAmazon SageMaker JumpStart
Open-source/Proprietary問わずモデルをサポート<br>
特にHugging Face上で公開されているモデルを多くサポート<br>
